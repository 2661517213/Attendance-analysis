import psycopg2
import re
from datetime import datetime, timedelta
import pandas as pd
from holidays import HOLIDAYS
from psycopg2 import sql
from config import DB_CONFIG
import sys

# å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒº
def flush_print(*args, **kwargs):
    """å¸¦ç¼“å†²åˆ·æ–°çš„printå‡½æ•°"""
    print(*args, **kwargs)
    sys.stdout.flush()

# ä¿®æ”¹pandasæ˜¾ç¤ºè®¾ç½®
pd.set_option('display.max_columns', None)  # æ˜¾ç¤ºæ‰€æœ‰åˆ—
pd.set_option('display.width', None)        # è®¾ç½®æ˜¾ç¤ºå®½åº¦ä¸ºæ— é™åˆ¶
pd.set_option('display.max_colwidth', None) # è®¾ç½®åˆ—å®½åº¦ä¸ºæ— é™åˆ¶
pd.set_option('display.max_rows', 50)       # æ˜¾ç¤º50è¡Œæ•°æ®
pd.set_option('display.min_rows', 50)       # æœ€å°‘æ˜¾ç¤º50è¡Œ

# åŸºç¡€å­—æ®µå®šä¹‰
basic_fields = ['å§“å', 'è€ƒå‹¤ç»„', 'éƒ¨é—¨', 'å·¥å·', 'èŒä½', 'UserId']
# ä¿®æ”¹ day_columns çš„å®šä¹‰ï¼Œä½¿ç”¨æ•°å­—æ ¼å¼
day_columns = [f"{i:02d}" for i in range(1, 32)]
all_columns = basic_fields + day_columns

# æ‰“å¡æ—¶é—´è§„åˆ™å¸¸é‡
MORNING_LIMIT = datetime.strptime("08:33", "%H:%M")
EVENING_LIMIT = datetime.strptime("18:00", "%H:%M")
HALF_DAY_ABSENT = timedelta(minutes=30)   # è¿Ÿåˆ°30åˆ†é’Ÿèµ·ç®—æ—·å·¥0.5å¤©
FULL_DAY_ABSENT = timedelta(hours=3)      # è¿Ÿåˆ°3å°æ—¶åŠä»¥ä¸Šç®—æ—·å·¥1å¤©
EARLY_LEAVE_THRESHOLD = timedelta(minutes=30)  # æ—©é€€30åˆ†é’Ÿåˆ¤å®šæ ‡å‡†

def get_db_connection():
    """åˆ›å»ºæ•°æ®åº“è¿æ¥"""
    return psycopg2.connect(**DB_CONFIG)

def process_excel_file(file_path, expected_columns=37):
    """
    å¤„ç†Excelæ–‡ä»¶ï¼šåªè¯»å–ç¬¬ä¸€ä¸ªsheetï¼Œä»ç¬¬4è¡Œå¼€å§‹è¯»å–ï¼Œåˆ é™¤ç©ºç™½è¡Œï¼Œç¡®ä¿æŒ‡å®šåˆ—æ•°
    
    å‚æ•°:
        file_path (str): Excelæ–‡ä»¶è·¯å¾„
        expected_columns (int): æœŸæœ›çš„åˆ—æ•°(é»˜è®¤ä¸º37)
    
    è¿”å›:
        pd.DataFrame: å¤„ç†åçš„DataFrame
    """
    try:
        # è¯»å–Excelæ–‡ä»¶ï¼Œè·³è¿‡å‰3è¡Œ
        df = pd.read_excel(file_path, sheet_name=0, skiprows=3)
        flush_print(f"âœ… åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape} (è¡ŒÃ—åˆ—)")
        
        # è®¾ç½®å‰6åˆ—çš„åˆ—å
        column_names = ['å§“å', 'è€ƒå‹¤ç»„', 'éƒ¨é—¨', 'å·¥å·', 'èŒä½', 'UserId']
        # ä»ç¬¬7åˆ—å¼€å§‹ï¼Œåˆ—åè®¾ç½®ä¸º01,02,03...
        remaining_columns = [f"{i:02d}" for i in range(1, len(df.columns)-5)]
        df.columns = column_names + remaining_columns
        
        # åˆ é™¤å®Œå…¨ç©ºç™½çš„è¡Œï¼ˆæ›´ä¸¥æ ¼çš„æ¸…ç†ï¼‰
        df_cleaned = df.dropna(how='all')
        # åˆ é™¤æ‰€æœ‰åˆ—éƒ½ä¸ºNaNæˆ–ç©ºå­—ç¬¦ä¸²çš„è¡Œ
        df_cleaned = df_cleaned.loc[~df_cleaned.apply(lambda x: x.isna().all() or (x == '').all(), axis=1)]
        
        # å¤„ç†åˆ—æ•°
        current_columns = len(df_cleaned.columns)
        
        if current_columns < expected_columns:
            # å¦‚æœåˆ—æ•°ä¸è¶³ï¼Œæ·»åŠ ç©ºåˆ—
            for i in range(current_columns, expected_columns):
                df_cleaned[f'ç©ºç™½åˆ—_{i+1}'] = None
            flush_print(f"âœ… å·²æ·»åŠ  {expected_columns - current_columns} ä¸ªç©ºç™½åˆ—")
        elif current_columns > expected_columns:
            # å¦‚æœåˆ—æ•°è¿‡å¤šï¼Œæˆªæ–­åˆ°æŒ‡å®šåˆ—æ•°
            df_cleaned = df_cleaned.iloc[:, :expected_columns]
            flush_print(f"âœ… å·²æˆªæ–­ {current_columns - expected_columns} åˆ—")
        
        # æœ€ç»ˆæ¸…ç†
        # 1. åˆ é™¤æ‰€æœ‰å®Œå…¨ä¸ºç©ºçš„è¡Œ
        df_cleaned = df_cleaned.dropna(how='all')
        # 2. é‡ç½®ç´¢å¼•
        df_cleaned = df_cleaned.reset_index(drop=True)
        # 3. åˆ é™¤æœ«å°¾çš„ç©ºè¡Œ
        last_valid_index = df_cleaned.apply(lambda x: x.notna().any() or (x != '').any(), axis=1).values.argmin()
        if last_valid_index > 0:
            df_cleaned = df_cleaned.iloc[:last_valid_index]
        
        # æ‰¾åˆ°æœ€åä¸€ä¸ªéç©ºè¡Œçš„ç´¢å¼•
        last_valid_row = None
        for idx in range(len(df_cleaned)-1, -1, -1):
            row = df_cleaned.iloc[idx]
            if not row.isna().all() and not (row == '').all():
                last_valid_row = idx
                break
        
        # åªä¿ç•™åˆ°æœ€åä¸€ä¸ªéç©ºè¡Œ
        if last_valid_row is not None:
            df_cleaned = df_cleaned.iloc[:last_valid_row + 1]
        
        flush_print(f"âœ… æœ€ç»ˆæ•°æ®å½¢çŠ¶: {df_cleaned.shape} (ç¡®ä¿ä¸º {expected_columns} åˆ—)")
        return df_cleaned
    except Exception as e:
        flush_print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None

def create_basic_table(conn, field_names):
    """åˆ›å»ºåŸºç¡€æ•°æ®è¡¨"""
    cursor = conn.cursor()
    
    try:
        # å…ˆåˆ é™¤å·²å­˜åœ¨çš„è¡¨
        cursor.execute("DROP TABLE IF EXISTS basic")
        conn.commit()
        
        # åˆ›å»ºè¡¨ï¼Œä½¿ç”¨å¤„ç†åçš„å­—æ®µå
        create_table_query = sql.SQL("CREATE TABLE basic ({})").format(
            sql.SQL(', ').join(
                sql.SQL("{} TEXT").format(sql.Identifier(col))  # ä½¿ç”¨TEXTç±»å‹è€Œä¸æ˜¯VARCHAR
                for col in field_names
            )
        )
        cursor.execute(create_table_query)
        conn.commit()
        flush_print("âœ… åŸºç¡€æ•°æ®è¡¨åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        flush_print(f"âŒ åˆ›å»ºåŸºç¡€è¡¨å¤±è´¥: {e}")
        conn.rollback()
    finally:
        cursor.close()

def save_basic_data_to_db(conn, processed_data, field_names):
    """å°†åŸºç¡€æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“"""
    cursor = conn.cursor()
    
    try:
        # æ„å»ºINSERTè¯­å¥
        insert_query = sql.SQL("INSERT INTO basic ({}) VALUES ({})").format(
            sql.SQL(', ').join(map(sql.Identifier, field_names)),
            sql.SQL(', ').join(sql.Placeholder() * len(field_names))
        )
        
        # æ’å…¥æ•°æ®
        for _, row in processed_data.iterrows():
            values = [str(val) if pd.notna(val) else None for val in row]  # ä½¿ç”¨Noneä»£æ›¿ç©ºå­—ç¬¦ä¸²
            cursor.execute(insert_query, values)
        
        conn.commit()
        flush_print("âœ… åŸºç¡€æ•°æ®å·²æˆåŠŸå¯¼å…¥PostgreSQLæ•°æ®åº“")
    except Exception as e:
        flush_print(f"âŒ ä¿å­˜åŸºç¡€æ•°æ®å¤±è´¥: {e}")
        conn.rollback()
    finally:
        cursor.close()

def create_result_table(conn):
    """åˆ›å»ºè€ƒå‹¤ç»“æœè¡¨"""
    cursor = conn.cursor()
    
    # åŸºç¡€å­—æ®µ
    basic_fields = ['å§“å', 'è€ƒå‹¤ç»„', 'éƒ¨é—¨', 'å·¥å·', 'èŒä½', 'UserId']
    # æ¯æ—¥è€ƒå‹¤å­—æ®µ
    day_fields = [f'ç¬¬{i}å¤©' for i in range(1, 32)]
    
    # æ‰€æœ‰å­—æ®µ(ç§»é™¤ç»Ÿè®¡å­—æ®µ)
    all_fields = basic_fields + day_fields
    
    # åˆ›å»ºè¡¨SQL
    create_table_sql = sql.SQL("CREATE TABLE IF NOT EXISTS attendance_result ({})").format(
        sql.SQL(', ').join(
            sql.SQL("{} TEXT").format(sql.Identifier(field))
            for field in all_fields
        )
    )
    
    try:
        cursor.execute("DROP TABLE IF EXISTS attendance_result")
        cursor.execute(create_table_sql)
        conn.commit()
        flush_print("âœ… è€ƒå‹¤ç»“æœè¡¨åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        flush_print(f"âŒ åˆ›å»ºè€ƒå‹¤ç»“æœè¡¨å¤±è´¥: {e}")
        conn.rollback()
    finally:
        cursor.close()

def save_results_to_db(conn, data):
    """å°†è€ƒå‹¤åˆ†æç»“æœä¿å­˜åˆ°æ•°æ®åº“"""
    cursor = conn.cursor()
    
    # å‡†å¤‡INSERTè¯­å¥
    fields = list(data[0].keys())
    insert_sql = sql.SQL("INSERT INTO attendance_result ({}) VALUES ({})").format(
        sql.SQL(', ').join(map(sql.Identifier, fields)),
        sql.SQL(', ').join(sql.Placeholder() * len(fields))
    )
    
    try:
        # æ‰¹é‡æ’å…¥æ•°æ®
        for row in data:
            # å¤„ç†nanå€¼
            values = [
                (str(val) if val not in (None, 'nan', 'None', '') else '')
                for val in row.values()
            ]
            cursor.execute(insert_sql, values)
        
        conn.commit()
        flush_print("âœ… è€ƒå‹¤åˆ†æç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“")
    except Exception as e:
        flush_print(f"âŒ ä¿å­˜è€ƒå‹¤ç»“æœå¤±è´¥: {e}")
        conn.rollback()
    finally:
        cursor.close()

def extract_times(cell):
    """æå– HH:MM æ ¼å¼çš„æ—¶é—´"""
    if not cell:
        return []
    times = re.findall(r"\d{2}:\d{2}", str(cell))
    return [datetime.strptime(t.strip(), "%H:%M") for t in times]

def analyze_day(cell, day):
    """åˆ†æå•æ—¥è€ƒå‹¤æƒ…å†µ"""
    times = extract_times(cell)
    
    # å¦‚æœæ˜¯ä¼‘æ¯æ—¥
    if f"{day:02d}" in HOLIDAYS:
        if not times:
            return ""
        else:
            return str(cell) if cell not in (None, 'nan', 'None') else ""
    
    # å·¥ä½œæ—¥é€»è¾‘
    if not times or len(times) < 2:
        if cell and cell not in (None, 'nan', 'None'):
            return f"ç¼ºå¡(1å¤©) {str(cell)}"
        return "ç¼ºå¡(1å¤©)"
    
    morning = min(times)
    evening = max(times)
    
    # åˆå§‹åŒ–è¿è§„æ—¶é•¿
    morning_late = timedelta()
    evening_early = timedelta()
    
    # è®¡ç®—è¿Ÿåˆ°æ—¶é•¿
    if morning > MORNING_LIMIT:
        morning_late = datetime.combine(datetime.today(), morning.time()) - \
                      datetime.combine(datetime.today(), MORNING_LIMIT.time())
    
    # è®¡ç®—æ—©é€€æ—¶é•¿ï¼ˆåªåœ¨ä¸‹åˆåˆ¤æ–­ï¼‰
    if evening.hour >= 12 and evening < EVENING_LIMIT:
        evening_early = datetime.combine(datetime.today(), EVENING_LIMIT.time()) - \
                       datetime.combine(datetime.today(), evening.time())
    
    times_str = f"({morning.strftime('%H:%M')}, {evening.strftime('%H:%M')})"
    
    # åˆ¤æ–­è€ƒå‹¤çŠ¶æ€
    # 1. ä¼˜å…ˆåˆ¤æ–­æ—·å·¥
    if morning_late >= FULL_DAY_ABSENT:
        return f"æ—·å·¥1å¤©{times_str}"
    elif HALF_DAY_ABSENT <= morning_late < FULL_DAY_ABSENT:
        return f"æ—·å·¥0.5å¤©{times_str}"
    
    # 2. åˆ¤æ–­è¿Ÿåˆ°å’Œæ—©é€€
    reasons = []
    if morning_late > timedelta():  # æœ‰è¿Ÿåˆ°å°±è®°å½•
        reasons.append("è¿Ÿåˆ°")
    if evening.hour >= 12 and evening_early >= EARLY_LEAVE_THRESHOLD:  # æ—©é€€å¿…é¡»æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶ï¼šåœ¨ä¸‹åˆä¸”æå‰30åˆ†é’Ÿä»¥ä¸Š
        reasons.append("æ—©é€€")
    
    # 3. è¿”å›æœ€ç»ˆç»“æœ
    if not reasons:
        return f"æ­£å¸¸{times_str}"
    else:
        return f"{'+'.join(reasons)}{times_str}"

def analyze_results(rows):
    """åˆ†æè€ƒå‹¤ç»“æœ"""
    data = []
    for row in rows:
        record = dict(zip(all_columns, row)) if isinstance(row, tuple) else row
        result_row = {key: record[key] for key in basic_fields}
        
        for i, col in enumerate(day_columns, start=1):
            result = analyze_day(record[col], i)
            result_row[f"ç¬¬{i}å¤©"] = result if result else ""
            
        data.append(result_row)
    return data

def main():
    flush_print("ğŸ”„ å¼€å§‹æ‰§è¡ŒåŸºç¡€æ•°æ®åˆå¹¶å¤„ç†...")
    flush_print("ğŸ“Š æ­£åœ¨è¿æ¥æ•°æ®åº“...")
    
    # è¿æ¥æ•°æ®åº“
    conn = get_db_connection()
    
    try:
        flush_print("ğŸ“ æ­£åœ¨å¤„ç†åŸå§‹Excelæ–‡ä»¶...")
        # 1. å¤„ç†åŸå§‹Excelæ–‡ä»¶
        input_file = "../data/original/basic.xlsx"
        processed_data = process_excel_file(input_file)
        
        if processed_data is None:
            raise Exception("Excelå¤„ç†å¤±è´¥")
        
        flush_print("ğŸ”§ æ­£åœ¨å¤„ç†å­—æ®µå...")
        # 2. å¤„ç†å­—æ®µå
        field_names = processed_data.columns.tolist()
        
        # å°†å­—æ®µåä¸­çš„ç‰¹æ®Šå­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œç¡®ä¿å­—æ®µåæœ‰æ•ˆ
        cleaned_field_names = []
        for name in field_names:
            # æ¸…ç†å­—æ®µå
            cleaned_name = str(name).strip()
            cleaned_name = cleaned_name.replace(' ', '_')
            cleaned_name = cleaned_name.replace('/', '_')
            cleaned_name = cleaned_name.replace('(', '')
            cleaned_name = cleaned_name.replace(')', '')
            cleaned_name = cleaned_name.replace('.', '_')
            cleaned_name = cleaned_name.replace('\n', '_')
            # ç¡®ä¿å­—æ®µåä»¥å­—æ¯å¼€å¤´
            if cleaned_name[0].isdigit():
                cleaned_name = 'column_' + cleaned_name  # ä¿®æ”¹å‰ç¼€ä¸º column_
            cleaned_field_names.append(cleaned_name)
        
        flush_print("ğŸ—„ï¸ æ­£åœ¨åˆ›å»ºåŸºç¡€æ•°æ®è¡¨...")
        # 3. åˆ›å»ºåŸºç¡€æ•°æ®è¡¨å¹¶ä¿å­˜æ•°æ®
        create_basic_table(conn, cleaned_field_names)
        save_basic_data_to_db(conn, processed_data, cleaned_field_names)
        
        flush_print("ğŸ“‹ æ­£åœ¨åˆ›å»ºè€ƒå‹¤ç»“æœè¡¨...")
        # 4. åˆ›å»ºè€ƒå‹¤ç»“æœè¡¨
        create_result_table(conn)
        
        flush_print("ğŸ” æ­£åœ¨åˆ†æè€ƒå‹¤æ•°æ®...")
        # 5. åˆ†æè€ƒå‹¤æ•°æ®
        data = analyze_results(processed_data.to_dict('records'))
        
        flush_print("ğŸ’¾ æ­£åœ¨ä¿å­˜è€ƒå‹¤åˆ†æç»“æœ...")
        # 6. ä¿å­˜è€ƒå‹¤åˆ†æç»“æœåˆ°æ•°æ®åº“
        save_results_to_db(conn, data)
        
        flush_print("âœ… åŸºç¡€æ•°æ®åˆå¹¶å¤„ç†å®Œæˆï¼")
        
    except Exception as e:
        flush_print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
    finally:
        conn.close()

if __name__ == "__main__":
    main() 